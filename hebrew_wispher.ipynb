{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio numpy torch transformers librosa soundfile tqdm googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import librosa\n",
    "import os\n",
    "import tempfile\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "model_name = 'ivrit-ai/whisper-large-v2-tuned'\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "processor = WhisperProcessor.from_pretrained(model_name)\n",
    "translator = Translator()\n",
    "\n",
    "def find_silent_sections(audio_data, sr, min_silence_length=0.5, silence_threshold=-40):\n",
    "    silent_sections = librosa.effects.split(audio_data, top_db=-silence_threshold)\n",
    "    silent_sections = [s for s in silent_sections if (s[1] - s[0]) >= min_silence_length * sr]\n",
    "    return silent_sections\n",
    "\n",
    "def split_into_paragraphs(text, min_words_per_paragraph=20):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    paragraphs = []\n",
    "    current_paragraph = \"\"\n",
    "    for sentence in sentences:\n",
    "        current_paragraph += sentence + \" \"\n",
    "        if len(current_paragraph.split()) >= min_words_per_paragraph:\n",
    "            paragraphs.append(current_paragraph.strip())\n",
    "            current_paragraph = \"\"\n",
    "    if current_paragraph:\n",
    "        paragraphs.append(current_paragraph.strip())\n",
    "    return paragraphs\n",
    "\n",
    "def transcribe_and_translate(audio_file, target_language):\n",
    "    audio, rate = librosa.load(audio_file, sr=None)\n",
    "    if rate != SAMPLING_RATE:\n",
    "        audio = librosa.resample(audio, orig_sr=rate, target_sr=SAMPLING_RATE)\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    chunks = np.array_split(audio, indices_or_sections=int(np.ceil(len(audio) / (SAMPLING_RATE * 30))))\n",
    "    transcribed_text = \"\"\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_path = os.path.join(temp_dir, f\"chunk_{i}.wav\")\n",
    "        sf.write(chunk_path, chunk, samplerate=SAMPLING_RATE)\n",
    "        chunk_audio, _ = librosa.load(chunk_path, sr=SAMPLING_RATE)\n",
    "        input_features = processor(chunk_audio, sampling_rate=SAMPLING_RATE, return_tensors=\"pt\").input_features.to(device)\n",
    "        predicted_ids = model.generate(input_features, num_beams=5)\n",
    "        chunk_text = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "        transcribed_text += chunk_text + \" \"\n",
    "    shutil.rmtree(temp_dir)\n",
    "    detected_language = translator.detect(transcribed_text).lang\n",
    "    if detected_language == 'he' and target_language != 'Hebrew':\n",
    "        transcribed_text = translator.translate(transcribed_text, src='he', dest=target_language.lower()).text\n",
    "    return transcribed_text\n",
    "\n",
    "title = 'Unlimited Length Transcription and Translation'\n",
    "description = 'This tool transcribes audio files and translates the transcription into the selected target language. It uses Whisper for transcription and Google Translate for translations involving Hebrew.'\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=transcribe_and_translate,\n",
    "    inputs=[gr.Audio(type='filepath', label='Upload Audio File'), gr.Dropdown(choices=['Hebrew', 'English', 'Spanish', 'French'], label='Target Language')],\n",
    "    outputs=gr.Textbox(label='Transcription / Translation'),\n",
    "    title=title,\n",
    "    description=description\n",
    ")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
