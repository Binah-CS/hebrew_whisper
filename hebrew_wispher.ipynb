{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio numpy torch transformers librosa soundfile tqdm googletrans==4.0.0-rc1 whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "import gradio as gr\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import soundfile as sf\n",
    "import tempfile\n",
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import whisper\n",
    "import datetime\n",
    "\n",
    "SAMPLING_RATE = 16000\n",
    "model_name = 'ivrit-ai/whisper-large-v2-tuned'\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "processor = WhisperProcessor.from_pretrained(model_name)\n",
    "translator = Translator()\n",
    "\n",
    "def transcribe(audio_file):\n",
    "    audio, rate = librosa.load(audio_file, sr=None)\n",
    "    if rate != SAMPLING_RATE:\n",
    "        audio = librosa.resample(audio, orig_sr=rate, target_sr=SAMPLING_RATE)\n",
    "\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    chunks = np.array_split(audio, indices_or_sections=int(np.ceil(len(audio) / (SAMPLING_RATE * 30))))  # 30s chunks\n",
    "    transcribed_text = \"\"\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_path = os.path.join(temp_dir, f\"chunk_{i}.wav\")\n",
    "        sf.write(chunk_path, chunk, samplerate=SAMPLING_RATE)\n",
    "        chunk_audio, _ = librosa.load(chunk_path, sr=SAMPLING_RATE)\n",
    "        input_features = processor(chunk_audio, sampling_rate=SAMPLING_RATE, return_tensors=\"pt\").input_features.to(device)\n",
    "        predicted_ids = model.generate(input_features, num_beams=5)\n",
    "        chunk_text = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "        transcribed_text += chunk_text + \" \"\n",
    "\n",
    "    shutil.rmtree(temp_dir)\n",
    "    return transcribed_text\n",
    "\n",
    "def translate_text(text, target_lang):\n",
    "    translations = {'Hebrew': 'he', 'English': 'en', 'Spanish': 'es', 'French': 'fr'}\n",
    "    translated_text = translator.translate(text, dest=translations[target_lang]).text\n",
    "    return translated_text\n",
    "    \n",
    "def split_into_paragraphs(text, min_words_per_paragraph=20):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    paragraphs = []\n",
    "    current_paragraph = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words_in_sentence = sentence.split()\n",
    "        current_paragraph.extend(words_in_sentence)\n",
    "        if len(current_paragraph) >= min_words_per_paragraph:\n",
    "            paragraphs.append(' '.join(current_paragraph))\n",
    "            current_paragraph = []\n",
    "\n",
    "    if current_paragraph:\n",
    "        paragraphs.append(' '.join(current_paragraph))\n",
    "\n",
    "    return '\\n\\n'.join(paragraphs)\n",
    "\n",
    "def generate_srt_content(audio_file_path, target_language='Hebrew', max_line_length=50):\n",
    "    print(\"Starting transcription and translation process...\")\n",
    "\n",
    "    audio, rate = librosa.load(audio_file_path, sr=None)\n",
    "    audio_numpy = librosa.resample(audio, orig_sr=rate, target_sr=16000)\n",
    "\n",
    "    temp_file_name = None\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmpfile:\n",
    "            temp_file_name = tmpfile.name\n",
    "            sf.write(tmpfile.name, audio_numpy, 16000)\n",
    "\n",
    "        transcription_result = whisper.load_model(\"large\").transcribe(audio=temp_file_name)\n",
    "\n",
    "        srt_content = \"\"\n",
    "        for segment in transcription_result['segments']:\n",
    "            start_time = str(datetime.timedelta(seconds=int(segment['start']))) + ',000'\n",
    "            end_time = str(datetime.timedelta(seconds=int(segment['end']))) + ',000'\n",
    "            text = segment['text']\n",
    "            segment_id = segment['id'] + 1\n",
    "\n",
    "            lines = []\n",
    "            while len(text) > max_line_length:\n",
    "                split_index = text.rfind(' ', 0, max_line_length)\n",
    "                if split_index == -1:\n",
    "                    split_index = max_line_length\n",
    "                lines.append(text[:split_index].strip())\n",
    "                text = text[split_index:].strip()\n",
    "            lines.append(text)\n",
    "\n",
    "            srt_entry = f\"{segment_id}\\n{start_time} --> {end_time}\\n\"\n",
    "            srt_entry += \"\\n\".join(lines) + \"\\n\\n\"\n",
    "            srt_content += srt_entry\n",
    "\n",
    "        hebrew_srt_content = translator.translate(srt_content, dest='he').text\n",
    "\n",
    "        os.makedirs(\"output\", exist_ok=True)\n",
    "        srt_file_path = os.path.join(\"output\", \"output.srt\")\n",
    "        with open(srt_file_path, \"w\", encoding=\"utf-8\") as srt_file:\n",
    "            srt_file.write(hebrew_srt_content)\n",
    "\n",
    "        return hebrew_srt_content\n",
    "\n",
    "    finally:\n",
    "        if temp_file_name:\n",
    "            os.remove(temp_file_name)\n",
    "\n",
    "def transcribe_and_translate(audio_file, target_language, generate_srt_checkbox):\n",
    "    translations = {'Hebrew': 'he', 'English': 'en', 'Spanish': 'es', 'French': 'fr'}\n",
    "    transcribed_text = transcribe(audio_file)\n",
    "    \n",
    "    # Apply paragraph splitting to the transcribed text\n",
    "    paragraphs = split_into_paragraphs(transcribed_text)\n",
    "    \n",
    "    detected_language_code = translator.detect(transcribed_text).lang\n",
    "\n",
    "    if generate_srt_checkbox:\n",
    "        srt_result = generate_srt_content(audio_file, 'Hebrew')\n",
    "        return srt_result\n",
    "    else:\n",
    "        if isinstance(target_language, list):\n",
    "            target_language = target_language[0]\n",
    "\n",
    "        if translations.get(target_language) != detected_language_code:\n",
    "            # Translate each paragraph separately\n",
    "            translated_paragraphs = [translate_text(paragraph, target_language) for paragraph in paragraphs]\n",
    "            # Join the translated paragraphs with double newline characters\n",
    "            final_text = '\\n\\n'.join(translated_paragraphs)\n",
    "        else:\n",
    "            final_text = '\\n\\n'.join(paragraphs)\n",
    "\n",
    "        return final_text\n",
    "\n",
    "title = \"Unlimited Length Transcription and Translation\"\n",
    "description = \"With ivrit-ai/whisper-large-v2-tuned | GUI by Shmuel Ronen\"\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=transcribe_and_translate,\n",
    "    inputs=[\n",
    "        gr.Audio(type=\"filepath\", label=\"Upload Audio File\"),\n",
    "        gr.Dropdown(choices=['Hebrew', 'English', 'Spanish', 'French'], label=\"Target Language\"),\n",
    "        gr.Checkbox(label=\"Generate Hebrew SRT File\")\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Transcription / Translation / SRT Result\"),\n",
    "    title=title,\n",
    "    description=description\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}