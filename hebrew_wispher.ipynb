{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio numpy torch transformers librosa soundfile tqdm googletrans==4.0.0-rc1 openai-whisper deep_translator nltk ffmpeg-python requests anthropic httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "import gradio as gr\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import soundfile as sf\n",
    "import tempfile\n",
    "import torch\n",
    "import time\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import whisper\n",
    "import datetime\n",
    "\n",
    "SAMPLING_RATE = 16000\n",
    "model_name = 'ivrit-ai/whisper-large-v2-tuned'\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "processor = WhisperProcessor.from_pretrained(model_name)\n",
    "translator = Translator()\n",
    "\n",
    "def transcribe(audio_numpy, sampling_rate=16000):\n",
    "    if audio_numpy.ndim > 1:\n",
    "        audio_numpy = audio_numpy.mean(axis=1)\n",
    "\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    chunks = np.array_split(audio_numpy, indices_or_sections=int(np.ceil(len(audio_numpy) / (sampling_rate * 30))))  # 30s chunks\n",
    "    transcribed_text = \"\"\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_path = os.path.join(temp_dir, f\"chunk_{i}.wav\")\n",
    "        sf.write(chunk_path, chunk, samplerate=sampling_rate)\n",
    "        input_features = processor(chunk, sampling_rate=sampling_rate, return_tensors=\"pt\").input_features.to(device)\n",
    "        predicted_ids = model.generate(input_features, num_beams=5)\n",
    "        chunk_text = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "        transcribed_text += chunk_text + \" \"\n",
    "\n",
    "    shutil.rmtree(temp_dir)\n",
    "    return transcribed_text\n",
    "\n",
    "def translate_text(text, target_lang):\n",
    "    translations = {'Hebrew': 'he', 'English': 'en', 'Spanish': 'es', 'French': 'fr'}\n",
    "    translated_text = translator.translate(text, dest=translations[target_lang]).text\n",
    "    return translated_text\n",
    "\n",
    "def split_into_paragraphs(text, min_words_per_paragraph=20):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    paragraphs = []\n",
    "    current_paragraph = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words_in_sentence = sentence.split()\n",
    "        current_paragraph.extend(words_in_sentence)\n",
    "        if len(current_paragraph) >= min_words_per_paragraph:\n",
    "            paragraphs.append(' '.join(current_paragraph))\n",
    "            current_paragraph = []\n",
    "\n",
    "    if current_paragraph:\n",
    "        paragraphs.append(' '.join(current_paragraph))\n",
    "\n",
    "    return '\\n\\n'.join(paragraphs)\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def generate_srt_content(audio_file_path, target_language='Hebrew', max_line_length=50):\n",
    "    print(\"Starting transcription and translation process...\")\n",
    "\n",
    "    audio = AudioSegment.from_file(audio_file_path)\n",
    "    audio_numpy = np.array(audio.get_array_of_samples(), dtype=np.float32) / 32768.0\n",
    "    audio_numpy = librosa.resample(audio_numpy, orig_sr=audio.frame_rate, target_sr=16000)\n",
    "\n",
    "    temp_file_name = None\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmpfile:\n",
    "            temp_file_name = tmpfile.name\n",
    "            sf.write(tmpfile.name, audio_numpy, 16000)\n",
    "\n",
    "        transcription_result = whisper.load_model(\"large\").transcribe(audio=temp_file_name)\n",
    "\n",
    "        srt_content = \"\"\n",
    "        for segment in transcription_result['segments']:\n",
    "            start_time = str(datetime.timedelta(seconds=int(segment['start']))) + ',000'\n",
    "            end_time = str(datetime.timedelta(seconds=int(segment['end']))) + ',000'\n",
    "            text = segment['text']\n",
    "            segment_id = segment['id'] + 1\n",
    "\n",
    "            lines = []\n",
    "            while len(text) > max_line_length:\n",
    "                split_index = text.rfind(' ', 0, max_line_length)\n",
    "                if split_index == -1:\n",
    "                    split_index = max_line_length\n",
    "                lines.append(text[:split_index].strip())\n",
    "                text = text[split_index:].strip()\n",
    "            lines.append(text)\n",
    "\n",
    "            srt_entry = f\"{segment_id}\\n{start_time} --> {end_time}\\n\"\n",
    "            \n",
    "            translated_lines = []\n",
    "            for line in lines:\n",
    "                for attempt in range(3):  # Retry translation up to 3 times\n",
    "                    try:\n",
    "                        translated_line = translator.translate(line, dest='he').text\n",
    "                        translated_lines.append(translated_line)\n",
    "                        break\n",
    "                    except Exception as e:\n",
    "                        print(f\"Translation failed (attempt {attempt+1}): {str(e)}\")\n",
    "                        if attempt < 2:\n",
    "                            time.sleep(1)  # Delay before retrying\n",
    "                        else:\n",
    "                            translated_lines.append(line)  # Use original English line if translation fails\n",
    "\n",
    "            srt_entry += \"\\n\".join(translated_lines) + \"\\n\\n\"\n",
    "            srt_content += srt_entry\n",
    "\n",
    "        os.makedirs(\"output\", exist_ok=True)\n",
    "        srt_file_path = os.path.join(\"output\", \"output.srt\")\n",
    "        with open(srt_file_path, \"w\", encoding=\"utf-8\") as srt_file:\n",
    "            srt_file.write(srt_content)\n",
    "\n",
    "        return srt_content\n",
    "\n",
    "    finally:\n",
    "        if temp_file_name:\n",
    "            os.remove(temp_file_name)\n",
    "\n",
    "def transcribe_and_translate(audio_file, target_language, generate_srt_checkbox):\n",
    "    if not target_language:\n",
    "        return \"Please choose a Target Language\"\n",
    "\n",
    "    translations = {'Hebrew': 'he', 'English': 'en', 'Spanish': 'es', 'French': 'fr'}\n",
    "\n",
    "    audio = AudioSegment.from_file(audio_file)\n",
    "    audio_numpy = np.array(audio.get_array_of_samples(), dtype=np.float32) / 32768.0\n",
    "    audio_numpy = librosa.resample(audio_numpy, orig_sr=audio.frame_rate, target_sr=16000)\n",
    "\n",
    "    transcribed_text = transcribe(audio_numpy)\n",
    "\n",
    "    if generate_srt_checkbox:\n",
    "        srt_result = generate_srt_content(audio_file, target_language)\n",
    "        return srt_result\n",
    "    else:\n",
    "        if isinstance(target_language, list):\n",
    "            target_language = target_language[0]\n",
    "\n",
    "        if translations.get(target_language) != 'he':\n",
    "            translated_text = translate_text(transcribed_text, target_language)\n",
    "            final_text = split_into_paragraphs(translated_text)\n",
    "        else:\n",
    "            final_text = split_into_paragraphs(transcribed_text)\n",
    "\n",
    "        os.makedirs(\"output\", exist_ok=True)\n",
    "        result_file_path = os.path.join(\"output\", \"result.txt\")\n",
    "        with open(result_file_path, \"w\", encoding=\"utf-8\") as result_file:\n",
    "            result_file.write(final_text)\n",
    "\n",
    "        return final_text\n",
    "\n",
    "title = \"Unlimited Length Transcription and Translation\"\n",
    "description = \"With ivrit-ai/whisper-large-v2-tuned | GUI by Shmuel Ronen\"\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=transcribe_and_translate,\n",
    "    inputs=[\n",
    "        gr.Audio(type=\"filepath\", label=\"Upload Audio File\"),\n",
    "        gr.Dropdown(choices=['Hebrew', 'English', 'Spanish', 'French'], label=\"Target Language\"),\n",
    "        gr.Checkbox(label=\"Generate Hebrew SRT File\")\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Transcription / Translation / SRT Result\"),\n",
    "    title=title,\n",
    "    description=description\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}